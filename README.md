# Awesome-Radiology-Report-Generation

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

We collect existing papers on radiology report generation published in prominent conferences and journals. 

This paper list will be continuously updated at the end of each month. 


## Table of Contents


- [Survey](#survey)
- [Papers](#papers)
  - [2024](#2024)
  - [2023](#2023)
  - [2022](#2022)
  - [2021](#2021)
  - [2020](#2020)
- [Other Resources](#other-resources)

## Survey

- Human Action Recognition from Various Data Modalities: A Review (**TPAMI 2022**) [[paper](https://ieeexplore.ieee.org/abstract/document/9795869)]

## Dataset
- MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs (**MIMIC-CXR**)  [[paper](https://arxiv.org/abs/1901.07042)][[data](https://physionet.org/content/mimic-cxr/2.0.0/)].
- Preparing a collection of radiology examinations for distribution and retrieval (**IU X-ray**) [[paper](https://academic.oup.com/jamia/article/23/2/304/2572395)][[data](https://openi.nlm.nih.gov/gridquery?q=pneumonia&it=xg&m=1&n=100)].
- Learning Visual-Semantic Embeddings for Reporting Abnormal Findings on Chest X-rays (**MIMIC-ABN**) [[paper](https://aclanthology.org/2020.findings-emnlp.176/)][[code](https://github.com/nijianmo/chest-xray-cvse)]

## Papers

Statistics: 🔥 relatively highly cited | ⭐ code is available and star > 100

### 2024

**AAAI**
- Automatic Radiology Reports Generation via Memory Alignment Network [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28279)] [code]
- PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28038)][[code]]
- Bootstrapping Large Language Models for Radiology Report Generation [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29826)] [[code](https://github.com/synlp/R2-LLM)]

**CVPR**
- ** [[paper]()] [[code]()]

**ACL**
- ** [[paper]()] [[code]()]

**EMNLP**
- ** [[paper]()] [[code]()]

**MICCAI**
- ** [[paper]()] [[code]()]

**BIBM**
- ** [[paper]()] [[code]()]

**ICASSP**
- ** [[paper]()] [[code]()]

**MedIA**
- ** [[paper]()] [[code]()]

**TMI**
- Multi-grained Radiology Report Generation with Sentence-level Image-language Contrastive Learning [[paper](https://ieeexplore.ieee.org/abstract/document/10458706)] [[code]()]

**TCSVT**
- ** [[paper]()] [[code]()]

**TNNLS**
- ** [[paper]()] [[code]()]

**TMM**
- ** [[paper]()] [[code]()]

**JBHI**
- ** [[paper]()] [[code]()]

**arXiv papers**
- FITA: Fine-grained Image-Text Aligner for Radiology Report Generation [[paper](https://arxiv.org/abs/2405.00962)] [[code]]
- GREEN: Generative Radiology Report Evaluation and Error Notation [[paper](https://arxiv.org/abs/2405.03595)] [[code]]
- CheXpert Plus: Hundreds of Thousands of Aligned Radiology Texts, Images and Patients [[paper](https://arxiv.org/abs/2405.19538)] [[code]]
- Topicwise Separable Sentence Retrieval for Medical Report Generation [[paper](https://arxiv.org/abs/2405.04175)] [[code]]

### 2023

**AAAI**
- ** [[paper]()] [[code]()]

**CVPR**
- KiUT: Knowledge-injected U-Transformer for Radiology Report Generation [[paper](https://ieeexplore.ieee.org/document/10203622)] [[code]]
- 

**ACL**
- ORGAN: Observation-Guided Radiology Report Generation via Tree Reasoning [[paper](https://arxiv.org/abs/2306.06466)] [[code](https://github.com/wjhou/ORGan)]

**EMNLP**
- RECAP: Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning [[paper](https://aclanthology.org/2023.findings-emnlp.140/)] [[code](https://github.com/wjhou/Recap)]

**MICCAI**
- ** [[paper]()] [[code]()]

**BIBM**
- ** [[paper]()] [[code]()]

**ICASSP**
- ** [[paper]()] [[code]()]
  
**MedIA**
- ** [[paper]()] [[code]()]

**TMI**
- Multi-grained Radiology Report Generation with Sentence-level Image-language Contrastive Learning [[paper](https://ieeexplore.ieee.org/abstract/document/10458706)] [[code]()]

**TCSVT**
- ** [[paper]()] [[code]()]

**TNNLS**
- ** [[paper]()] [[code]()]

**TMM**
- From Observation to Concept: A Flexible Multi-view Paradigm for Medical Report Generation [[paper](https://ieeexplore.ieee.org/abstract/document/10356722)] [[code]]

**JBHI**
- ** [[paper]()] [[code]()]

**arXiv papers**
- ** [[paper]()] [[code]()]

### 2022

**AAAI**
- ** [[paper]()] [[code]()]

**CVPR**
- ** [[paper]()] [[code]()]

**ACL**
- ** [[paper]()] [[code]()]

**EMNLP**
- ** [[paper]()] [[code]()]

**MICCAI**
- ** [[paper]()] [[code]()]

**BIBM**
- ** [[paper]()] [[code]()]

**ICASSP**
- ** [[paper]()] [[code]()]

**MedIA**
- ** [[paper]()] [[code]()]

**TMI**
- ** [[paper]()] [[code]()]

**TCSVT**
- ** [[paper]()] [[code]()]

**TNNLS**
- ** [[paper]()] [[code]()]
  
**TMM**
- ** [[paper]()] [[code]()]

**JBHI**
- ** [[paper]()] [[code]()]


**arXiv papers**
- ** [[paper]()] [[code]()]

### 2021

**AAAI**
- ** [[paper]()] [[code]()]

**CVPR**
- ** [[paper]()] [[code]()]

**ACL**
- ** [[paper]()] [[code]()]

**EMNLP**
- ** [[paper]()] [[code]()]

**MICCAI**
- ** [[paper]()] [[code]()]

**BIBM**
- ** [[paper]()] [[code]()]

**ICASSP**
- ** [[paper]()] [[code]()]

**MedIA**
- ** [[paper]()] [[code]()]

**TMI**
- ** [[paper]()] [[code]()]

**TCSVT**
- ** [[paper]()] [[code]()]

**TNNLS**
- ** [[paper]()] [[code]()]

**TMM**
- ** [[paper]()] [[code]()]

**JBHI**
- ** [[paper]()] [[code]()]


**arXiv papers**
- ** [[paper]()] [[code]()]

### 2020

**AAAI**
- ** [[paper]()] [[code]()]

**CVPR**
- ** [[paper]()] [[code]()]

**ACL**
- ** [[paper]()] [[code]()]

**EMNLP**
- ** [[paper]()] [[code]()]

**MICCAI**
- ** [[paper]()] [[code]()]

**BIBM**
- ** [[paper]()] [[code]()]

**ICASSP**
- ** [[paper]()] [[code]()]
  
**MedIA**
- ** [[paper]()] [[code]()]

**TMI**
- ** [[paper]()] [[code]()]

**TCSVT**
- ** [[paper]()] [[code]()]

**TNNLS**
- ** [[paper]()] [[code]()]

**TMM**
- ** [[paper]()] [[code]()]

**JBHI**
- ** [[paper]()] [[code]()]


**arXiv papers**
- ** [[paper]()] [[code]()]



## Other Resources
With all the resources available on the Github website, this paper list is comprehensive and recently updated.

- [**]()

## Last update: Mar 18, 2024

## Feel free to contact me if you find any interesting papers are missing.
